{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the scikit-learn function to load the open diabetes dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "# Loads the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "# Extracts the features and the target variable\n",
    "X, y = diabetes['data'], diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the pandas library to convert the sk learn dataset into a pandas dataframe\n",
    "import pandas as pd\n",
    "# Mapping the feature names provided by Scikit-Learn to a more readable form\n",
    "feature_rename = {'age' : 'Age',\n",
    "                  'sex' : 'Sex',\n",
    "                  'bmi' : 'BMI',\n",
    "                  'bp': 'BP',\n",
    "                  's1': 'Total Cholesterol',\n",
    "                  's2': 'LDL',\n",
    "                  's3': 'HDL',\n",
    "                  's4': 'Thyroid',\n",
    "                  's5': 'Glaucoma',\n",
    "                  's6': 'Glucose'}\n",
    "\n",
    "# Loads all the features (x) into a dataframe. \n",
    "# Uses the sk-learn feature names as column names\n",
    "df_data = pd.DataFrame(X, columns = diabetes['feature_names'])\n",
    "\n",
    "# Renames the sk-learn feature names to a more readable form\n",
    "df_data.rename(columns = feature_rename, inplace = True)\n",
    "\n",
    "# Stores the list\n",
    "feature_names = list(df_data.columns.values)\n",
    "\n",
    "# Includes the target varable (y) as a separate column\n",
    "df_data['target'] = y              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975d7d6",
   "metadata": {},
   "source": [
    "### Plotting the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7114c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variable to store the correlation matrix\n",
    "corr = df_data.corr()\n",
    "\n",
    "# Imports Matplotlib and SEaborn to plot the correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = 'whitegrid')\n",
    "sns.set_palette('bright')\n",
    "\n",
    "# Imitializes a Matplotlib plot with a predefined size\n",
    "f, ax = plt.subplots(figsize = (10, 10))\n",
    "# Uses Seaborn to plot a heatmap of the correlation coefficients\n",
    "sns.heatmap(corr,\n",
    "            vmin = -1, vmax = 1, center = 0,\n",
    "            cmap = 'PiYG',\n",
    "            square = True,\n",
    "            ax = ax)\n",
    "\n",
    "# Shows the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219d6a4",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports numpy to evaluate the performance of model\n",
    "import numpy as np\n",
    "# Imports the scikit-learn class for linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Imports the scikit-learn function to split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splits the data into training and test sets, where 80% of the data is used for training and 20% of the data for testing, and ensures that the seed for the random- number generator is set using the random_state parameter to ensure consistent train-test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# Initializes the linear regression model, which is based on least squares\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Learns the weights for the model by fitting on the training set\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Uses the learned weights to predict the disease progression for patients in the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluates the model performance using the mean absolute error (MAE) metric\n",
    "mae = np.mean(np.abs(y_test - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6ebb0",
   "metadata": {},
   "source": [
    "### Feature importance for the diabetes linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports numpy to perform operation on vectors in an optimized way\n",
    "#  import numpy as np (not needed)\n",
    "# Imports matplotlib and seaborn to plot the feature importance\n",
    "#  import matplotlib.pyplot as plt (not needed)\n",
    "#  import seaborn as sns (not needed)\n",
    "#  sns.set(style=’whitegrid’) (not needed)\n",
    "#  sns.set_palette(‘bright’) (not needed)\n",
    "\n",
    "# Obtains the weights from the linear regression model trained earlier using the coef_ parameter\n",
    "weights = lr_model.coef_\n",
    "\n",
    "# Sorts the weights in descending order of importance and gets their indices\n",
    "feature_importance_idx = np.argsort(np.abs(weights))[::-1]\n",
    "\n",
    "# Uses the ordered indices to get the feature names and the corresponding weight values\n",
    "feature_importance = [feature_names[idx].upper() for idx in feature_importance_idx]\n",
    "feature_importance_values = [weights[idx] for idx in feature_importance_idx]\n",
    "\n",
    "# Generates the plot\n",
    "f, ax = plt.subplots(figsize=(10, 8)) \n",
    "sns.barplot(x=feature_importance_values, y=feature_importance, ax=ax) \n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Feature Weights')\n",
    "ax.set_ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0ba1e",
   "metadata": {},
   "source": [
    "* The most important feature is the Total Cholesterol measurement. It has a large negative value for the weight. This means that a positive change in the cholesterol level has a large negative influence on predicting diabetes progression. This could be because Total Cholesterol also accounts for the good kind of cholesterol.\n",
    "\n",
    "\n",
    "* If we now look at the bad cholesterol, or LDL, feature, it has a large positive weight, and it is also the fourth most important feature in predicting the progression of diabetes. This means that a positive change in LDL cholesterol level results in a large positive influence in predicting diabetes one year out.\n",
    "\n",
    "\n",
    "* The good cholesterol, or HDL, feature has a small positive weight and is the third least important feature because if we observe the correlation among total cholesterol, LDL, and HDL, we see a very high correlation between total cholesterol and LDL and moderately high correlation between total cholesterol and HDL. Because of this correlation, the HDL feature is deemed redundant by the model.\n",
    "\n",
    "\n",
    "* It also looks like the baseline Glucose measurement for the patient has a very small impact on predicting the progression of diabetes a year out. because Glucose measurement is very highly correlated with the baseline Glaucoma measurement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
